{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68347813",
   "metadata": {},
   "source": [
    "# Movie Ratings Prediction using Non-Negative Matrix Factorization\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "### Objective\n",
    "This project explores the application of **Non-Negative Matrix Factorization (NMF)** for predicting missing movie ratings and investigates the limitations of sklearn's NMF implementation compared to traditional recommender system approaches.\n",
    "\n",
    "### Problem Statement\n",
    "**Limitation(s) of sklearn's non-negative matrix factorization library** \n",
    "\n",
    "#### Part 1: NMF Implementation \n",
    "- Load the movie ratings dataset (from HW3-recommender-system)\n",
    "- Apply sklearn's Non-Negative Matrix Factorization (NMF) technique\n",
    "- Predict missing ratings from the test data\n",
    "- Measure prediction performance using **RMSE**\n",
    "\n",
    "#### Part 2: Critical Analysis \n",
    "- Analyze and discuss the results obtained from sklearn's NMF\n",
    "- Compare performance with baseline and similarity-based methods from Module 3\n",
    "- Identify why NMF may underperform compared to simpler approaches\n",
    "- Propose potential solutions and improvements to enhance NMF performance\n",
    "\n",
    "### Dataset\n",
    "-  [MovieLense](https://grouplens.org/datasets/movielens/) has currently 25 million user-movie ratings.  Since the entire data is too big, we use  a 1 million ratings subset [MovieLens 1M](https://www.kaggle.com/odedgolden/movielens-1m-dataset), and we reformatted the data to make it more convenient to use.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d36b204",
   "metadata": {},
   "source": [
    "# 1. Load the movie ratings dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb8902a",
   "metadata": {},
   "source": [
    "## 2. Part 1: NMF Implementation [10 pts]\n",
    "\n",
    "### 2.1 Create Utility Matrix\n",
    "\n",
    "First, we need to convert the training data into a user-item rating matrix that NMF can process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eda4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create mapping dictionaries\n",
    "allusers = list(data.users['uID'])\n",
    "allmovies = list(data.movies['mID'])\n",
    "\n",
    "mid2idx = dict(zip(data.movies.mID, list(range(len(data.movies)))))\n",
    "uid2idx = dict(zip(data.users.uID, list(range(len(data.users)))))\n",
    "\n",
    "# Convert train data to utility matrix\n",
    "ind_movie = [mid2idx[x] for x in data.train.mID]\n",
    "ind_user = [uid2idx[x] for x in data.train.uID]\n",
    "rating_train = list(data.train.rating)\n",
    "\n",
    "# Create rating matrix as numpy array\n",
    "Mr = np.array(coo_matrix((rating_train, (ind_user, ind_movie)), \n",
    "                          shape=(len(allusers), len(allmovies))).toarray())\n",
    "\n",
    "print(f\"Utility Matrix Shape: {Mr.shape}\")\n",
    "print(f\"Number of users: {len(allusers)}\")\n",
    "print(f\"Number of movies: {len(allmovies)}\")\n",
    "print(f\"Number of ratings in train: {len(rating_train)}\")\n",
    "print(f\"Matrix sparsity: {(Mr == 0).sum() / Mr.size * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4310f5",
   "metadata": {},
   "source": [
    "### 2.2 Apply NMF for Matrix Factorization\n",
    "\n",
    "NMF decomposes the rating matrix R into two non-negative matrices:\n",
    "- **W (User-Factor matrix)**: Shape (n_users, n_components)\n",
    "- **H (Factor-Movie matrix)**: Shape (n_components, n_movies)\n",
    "\n",
    "The predicted ratings are obtained by: **R_pred = W √ó H**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3590f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF requires non-negative values, so we replace 0s (unrated) with a small positive value\n",
    "# This is a common preprocessing step for NMF\n",
    "Mr_nmf = Mr.copy()\n",
    "Mr_nmf[Mr_nmf == 0] = 0.01  # Replace 0 with small positive value\n",
    "\n",
    "# Apply NMF with different numbers of components\n",
    "n_components = 20  # Number of latent factors\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"APPLYING NMF FOR MATRIX FACTORIZATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Number of components (latent factors): {n_components}\")\n",
    "print()\n",
    "\n",
    "# Initialize and fit NMF model\n",
    "nmf_model = NMF(n_components=n_components, \n",
    "                init='random',\n",
    "                random_state=42,\n",
    "                max_iter=200,\n",
    "                verbose=1)\n",
    "\n",
    "W = nmf_model.fit_transform(Mr_nmf)\n",
    "H = nmf_model.components_\n",
    "\n",
    "print(f\"\\nW (User-Factor) matrix shape: {W.shape}\")\n",
    "print(f\"H (Factor-Movie) matrix shape: {H.shape}\")\n",
    "print(f\"Reconstruction error: {nmf_model.reconstruction_err_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469eb345",
   "metadata": {},
   "source": [
    "### 2.3 Predict Missing Ratings on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bcac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the full rating matrix\n",
    "R_pred = np.dot(W, H)\n",
    "\n",
    "# Predict ratings for test set\n",
    "predictions = []\n",
    "for idx, row in data.test.iterrows():\n",
    "    uid = row['uID']\n",
    "    mid = row['mID']\n",
    "    \n",
    "    user_idx = uid2idx[uid]\n",
    "    movie_idx = mid2idx[mid]\n",
    "    \n",
    "    predicted_rating = R_pred[user_idx, movie_idx]\n",
    "    predictions.append(predicted_rating)\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Handle NaN values by replacing with mean rating\n",
    "predictions[np.isnan(predictions)] = 3.0\n",
    "\n",
    "# Clip predictions to valid rating range [1, 5]\n",
    "predictions = np.clip(predictions, 1, 5)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PREDICTION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Number of test samples: {len(data.test)}\")\n",
    "print(f\"Predicted ratings range: [{predictions.min():.2f}, {predictions.max():.2f}]\")\n",
    "print(f\"Mean predicted rating: {predictions.mean():.2f}\")\n",
    "print()\n",
    "print(\"Sample predictions:\")\n",
    "print(data.test.head(10).assign(predicted_rating=predictions[:10]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57c79c6",
   "metadata": {},
   "source": [
    "### 2.4 Calculate RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782cbed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE\n",
    "actual_ratings = np.array(data.test.rating)\n",
    "rmse_nmf = np.sqrt(((actual_ratings - predictions)**2).mean())\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PERFORMANCE EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"NMF RMSE: {rmse_nmf:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Visualize prediction errors\n",
    "errors = actual_ratings - predictions\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(actual_ratings, predictions, alpha=0.3, s=1)\n",
    "plt.plot([1, 5], [1, 5], 'r--', label='Perfect prediction')\n",
    "plt.xlabel('Actual Rating')\n",
    "plt.ylabel('Predicted Rating')\n",
    "plt.title('Actual vs Predicted Ratings')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Prediction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Prediction Errors')\n",
    "plt.axvline(x=0, color='r', linestyle='--', label='Zero error')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.boxplot([errors], labels=['NMF'])\n",
    "plt.ylabel('Prediction Error')\n",
    "plt.title('Error Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7505a2b1",
   "metadata": {},
   "source": [
    "## 3. Part 2: Critical Analysis and Comparison [10 pts]\n",
    "\n",
    "### 3.1 Performance Comparison with HW3 Methods\n",
    "\n",
    "Let's compare NMF performance with the baseline and similarity-based methods from Module 3 (HW3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ad27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison table (from HW3 results)\n",
    "comparison_data = {\n",
    "    'Method': [\n",
    "        'Baseline: Predict all to 3',\n",
    "        'Baseline: User average',\n",
    "        'Content-Based (Jaccard)',\n",
    "        'Collaborative Filtering (Cosine)',\n",
    "        'Collaborative Filtering (Jaccard, Mr‚â•3)',\n",
    "        'Collaborative Filtering (Jaccard, Mr‚â•1)',\n",
    "        'Collaborative Filtering (Jaccard, Mr)',\n",
    "        'NMF (sklearn)'\n",
    "    ],\n",
    "    'RMSE': [\n",
    "        1.258,  # From HW3\n",
    "        1.035,  # From HW3\n",
    "        1.012,  # From HW3\n",
    "        1.024,  # From HW3\n",
    "        0.982,  # From HW3\n",
    "        0.991,  # From HW3\n",
    "        0.952,  # From HW3 (Best)\n",
    "        rmse_nmf  # Our NMF result\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('RMSE')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PERFORMANCE COMPARISON: NMF vs HW3 METHODS\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['#ff6b6b' if method == 'NMF (sklearn)' else '#4ecdc4' \n",
    "          for method in comparison_df['Method']]\n",
    "bars = plt.barh(comparison_df['Method'], comparison_df['RMSE'], color=colors)\n",
    "plt.xlabel('RMSE (Lower is Better)', fontsize=12)\n",
    "plt.title('Performance Comparison: NMF vs Similarity-Based Methods', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=1.0, color='gray', linestyle='--', alpha=0.5, label='RMSE = 1.0')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate performance gap\n",
    "best_hw3_rmse = comparison_df[comparison_df['Method'] != 'NMF (sklearn)']['RMSE'].min()\n",
    "performance_gap = ((rmse_nmf - best_hw3_rmse) / best_hw3_rmse) * 100\n",
    "\n",
    "print(f\"\\nüîç Performance Gap:\")\n",
    "print(f\"   Best HW3 method: {best_hw3_rmse:.4f}\")\n",
    "print(f\"   NMF (sklearn): {rmse_nmf:.4f}\")\n",
    "print(f\"   Gap: +{performance_gap:.2f}% worse than best HW3 method\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c28598",
   "metadata": {},
   "source": [
    "### 3.2 Why sklearn's NMF Underperforms\n",
    "\n",
    "#### Key Limitations:\n",
    "\n",
    "**1. Non-Negativity Constraint is Too Restrictive**\n",
    "- NMF requires all values ‚â• 0, which doesn't align well with rating prediction\n",
    "- User preferences can be negative (dislike), but NMF cannot capture this\n",
    "- Similarity-based methods can use negative correlations effectively\n",
    "\n",
    "**2. Sparse Matrix Handling**\n",
    "- The rating matrix is 95%+ sparse (most users haven't rated most movies)\n",
    "- NMF treats missing ratings (0s) as actual data points when we fill them with 0.01\n",
    "- This introduces massive noise: ~95% of the \"training data\" is artificial!\n",
    "- Similarity-based methods ignore unrated items, focusing only on actual ratings\n",
    "\n",
    "**3. Loss of User/Item-Specific Information**\n",
    "- NMF reduces users and movies to k latent factors\n",
    "- Important user-specific or item-specific patterns may be lost in this compression\n",
    "- Similarity-based methods preserve the original rating patterns\n",
    "\n",
    "**4. Global Optimization vs Local Patterns**\n",
    "- NMF optimizes a global reconstruction error across the entire matrix\n",
    "- It may sacrifice accuracy on specific user-movie pairs to minimize overall error\n",
    "- Similarity-based methods make predictions based on local neighborhoods\n",
    "\n",
    "**5. No Mean-Centering**\n",
    "- sklearn's NMF doesn't handle user/item biases (some users rate high, some rate low)\n",
    "- Collaborative filtering methods center ratings by user means\n",
    "- This removes systematic biases before calculating similarities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a45a29",
   "metadata": {},
   "source": [
    "### 3.3 Proposed Solutions to Improve NMF Performance\n",
    "\n",
    "#### Solution 1: Use Specialized Recommendation Libraries\n",
    "Instead of sklearn's generic NMF, use libraries designed for recommender systems:\n",
    "\n",
    "```python\n",
    "# Example using Surprise library\n",
    "from surprise import SVD, NMF as SurpriseNMF\n",
    "from surprise import Dataset, Reader\n",
    "\n",
    "# Surprise's NMF handles sparse matrices properly\n",
    "# It only trains on observed ratings (not filling 0s)\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- Only trains on actual ratings (sparse matrix optimization)\n",
    "- Includes user/item bias terms\n",
    "- Regularization to prevent overfitting\n",
    "\n",
    "---\n",
    "\n",
    "#### Solution 2: Preprocess Ratings with Mean-Centering\n",
    "```python\n",
    "# Center ratings by user mean before NMF\n",
    "user_means = Mr.sum(axis=1) / (Mr > 0).sum(axis=1)\n",
    "Mr_centered = Mr - user_means[:, np.newaxis]\n",
    "Mr_centered[Mr == 0] = 0  # Keep unrated as 0\n",
    "\n",
    "# Apply NMF on centered data\n",
    "# Add user means back after prediction\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- Removes user rating biases\n",
    "- NMF can focus on relative preferences\n",
    "\n",
    "---\n",
    "\n",
    "#### Solution 3: Hybrid Approach\n",
    "Combine NMF with similarity-based methods:\n",
    "\n",
    "```python\n",
    "# Use NMF for dimensionality reduction\n",
    "W_nmf, H_nmf = apply_nmf(Mr)\n",
    "\n",
    "# Calculate similarities in the reduced space\n",
    "# Then use neighborhood-based prediction\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- Leverages NMF's ability to find latent factors\n",
    "- Uses similarity-based method's local prediction accuracy\n",
    "\n",
    "---\n",
    "\n",
    "#### Solution 4: Weighted Matrix Factorization\n",
    "Give higher weight to observed ratings:\n",
    "\n",
    "```python\n",
    "# Create weight matrix\n",
    "W_matrix = (Mr > 0).astype(float)  # 1 for observed, 0 for missing\n",
    "\n",
    "# Use weighted NMF or implement custom loss\n",
    "# sklearn doesn't support this natively\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- Focuses learning on actual ratings\n",
    "- Doesn't treat missing ratings as data points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da03111b",
   "metadata": {},
   "source": [
    "### 3.4 Summary and Conclusion\n",
    "\n",
    "#### Key Findings:\n",
    "\n",
    "| Aspect | Similarity-Based Methods (HW3) | sklearn NMF |\n",
    "|--------|-------------------------------|-------------|\n",
    "| **Best RMSE** | 0.952 | ~1.18 (24% worse) |\n",
    "| **Sparse Matrix Handling** | ‚úÖ Ignores missing ratings | ‚ùå Fills with artificial values |\n",
    "| **User Biases** | ‚úÖ Mean-centered | ‚ùå No bias handling |\n",
    "| **Flexibility** | ‚úÖ Can use negative correlations | ‚ùå Non-negativity constraint |\n",
    "| **Prediction Strategy** | ‚úÖ Local neighborhoods | ‚ùå Global reconstruction |\n",
    "| **Complexity** | Simple, interpretable | More complex |\n",
    "\n",
    "#### Why Similarity-Based Methods Win:\n",
    "\n",
    "1. **Designed for Sparse Data**: Only use actual ratings, no artificial fill values\n",
    "2. **Local Context**: Predictions based on similar users/items, not global patterns\n",
    "3. **Bias Handling**: Remove systematic user/item biases before calculation\n",
    "4. **Flexibility**: Can capture both positive and negative relationships\n",
    "\n",
    "#### When NMF Could Be Useful:\n",
    "\n",
    "- **Dense matrices** with few missing values\n",
    "- **Topic modeling** where non-negativity makes sense\n",
    "- **Dimensionality reduction** before applying other methods\n",
    "- **When combined** with proper sparse matrix techniques and bias handling\n",
    "\n",
    "#### Recommendation:\n",
    "\n",
    "For movie rating prediction with sparse data:\n",
    "- ‚úÖ **Use similarity-based methods** (Collaborative Filtering)\n",
    "- ‚úÖ Or use specialized libraries like **Surprise** or **LightFM**\n",
    "- ‚ùå **Avoid sklearn's NMF** without significant preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ec94f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b3d657c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    uID   mID  rating\n",
      "0   744  1210       5\n",
      "1  3040  1584       4\n",
      "2  1451  1293       5\n",
      "3  5455  3176       2\n",
      "4  2507  3074       5\n",
      "    uID   mID  rating\n",
      "0  2233   440       4\n",
      "1  4274   587       5\n",
      "2  2498   454       3\n",
      "3  2868  2336       5\n",
      "4  1636  2686       5\n"
     ]
    }
   ],
   "source": [
    "MV_users = pd.read_csv('../data/users.csv')\n",
    "MV_movies = pd.read_csv('../data/movies.csv')\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "\n",
    "Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "data = Data(MV_users, MV_movies, train, test)\n",
    "# print(data.movies.info())\n",
    "# print(data.users.info())\n",
    "print(data.train.head())    \n",
    "print(data.test.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
